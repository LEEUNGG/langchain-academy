{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join(os.path.abspath(os.path.join(os.getcwd(), \"..\")), \".env\"))\n",
    "\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Start conversation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhi! I\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mm Lance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langgraph/pregel/main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mcall_model\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     34\u001b[39m     messages = state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: response}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1023\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m     **kwargs: Any,\n\u001b[32m   1021\u001b[39m ) -> LLMResult:\n\u001b[32m   1022\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:840\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    839\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m         )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    848\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1089\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1087\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1184\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1183\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1186\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1187\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1188\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1189\u001b[39m ):\n\u001b[32m   1190\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1179\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1172\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1173\u001b[39m             response,\n\u001b[32m   1174\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1175\u001b[39m             metadata=generation_info,\n\u001b[32m   1176\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1177\u001b[39m         )\n\u001b[32m   1178\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1179\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1180\u001b[39m         response = raw_response.parse()\n\u001b[32m   1181\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Code/langchain-academy/.venv/lib/python3.11/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
      "During task with name 'conversation' and id 'a5ffef05-702a-fdf1-f990-b3124cf62b9e'"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! How are you doing today?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! How can I assist you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l9/bpjxdmfx7lvd1fbdjn38y5dh0000gn/T/ipykernel_66136/946416104.py:3: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: __start__. Type: on_chain_start. Name: __start__\n",
      "Node: __start__. Type: on_chain_end. Name: __start__\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chain_start. Name: ChannelWrite<conversation,messages,summary>\n",
      "Node: conversation. Type: on_chain_end. Name: ChannelWrite<conversation,messages,summary>\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' San', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' a', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' professional', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' American', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' football', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' based', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' San', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bay', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Area', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' They', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' compete', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' National', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Football', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' League', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' (', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='NFL', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=')', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' as', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' a', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' member', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' league', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' National', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Football', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' (', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='N', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='FC', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=')', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' West', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' division', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Here', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' some', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' key', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' points', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' about', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' History', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Founded', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='194', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='6', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Joined', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='194', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='9', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' as', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' part', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' merger', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' between', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' All', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-Amer', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ica', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Football', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' (', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='AA', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='FC', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=')\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Name', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Origin', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' name', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' \"', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\"', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' is', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' a', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' reference', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' to', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' prospect', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ors', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' who', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' arrived', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Northern', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' California', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' during', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='184', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='9', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Gold', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Rush', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Ach', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ievements', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Super', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Championships', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' have', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' won', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' five', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Super', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' titles', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' (', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='X', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='VI', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' XIX', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' XX', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='III', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' XX', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='IV', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' XX', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='IX', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=').\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Conference', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Championships', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' They', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' have', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' won', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFC', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Championship', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' seven', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' times', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Division', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Championships', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' has', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFC', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' West', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' division', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' titles', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Not', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='able', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Figures', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Joe', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Montana', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' who', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' led', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' to', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' four', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Super', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' victories', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Jerry', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Rice', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Wid', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ely', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' considered', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' greatest', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' wide', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' receiver', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' history', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Steve', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Young', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Another', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' who', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' led', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' to', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' a', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Super', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' victory', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Bill', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Walsh', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Legendary', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' head', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' coach', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' known', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' for', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' developing', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' \"', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='West', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Coast', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Off', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ense', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\"\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Home', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Le', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='vi', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Located', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Santa', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Clara', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' California', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' it', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' has', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' been', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=\" team's\", id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' home', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' since', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='201', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='4', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Prior', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' to', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' that', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' they', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' played', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' at', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Cand', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='lestick', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Park', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' San', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Colors', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Masc', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ot', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Colors', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Red', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' gold', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' white', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Masc', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ot', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' S', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ourd', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ough', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Sam', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Recent', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Performance', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' have', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' experienced', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' various', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' periods', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' success', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' rebuilding', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' They', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' reached', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Super', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='201', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='9', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' season', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' but', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' were', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' defeated', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' by', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Kansas', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' City', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Chiefs', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' has', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' been', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' competitive', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' recent', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' years', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' often', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' cont', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ending', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' for', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' playoff', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' spots', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Community', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Culture', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' have', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' a', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' strong', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' fan', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' base', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' known', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' for', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' their', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' rich', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' history', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' tradition', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' They', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' also', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' active', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' community', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' service', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' charitable', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' activities', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' through', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Foundation', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Rival', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ries', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' have', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' notable', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' rival', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ries', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' with', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' several', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' teams', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' including', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Dallas', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Cowboys', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Seattle', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Seahawks', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Los', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Angeles', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Rams', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' These', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' rival', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ries', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' often', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' marked', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' by', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' intense', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' memorable', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' games', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Overall', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' San', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' one', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' most', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' stor', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ied', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' franchises', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' history', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' known', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' for', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' their', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' success', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='198', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='0', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='s', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='199', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='0', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='s', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' their', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' continued', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' pursuit', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' excellence', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' on', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' field', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'}, id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| San| Francisco| |49|ers| are| a| professional| American| football| team| based| in| the| San| Francisco| Bay| Area|.| They| compete| in| the| National| Football| League| (|NFL|)| as| a| member| of| the| league|'s| National| Football| Conference| (|N|FC|)| West| division|.| Here| are| some| key| points| about| the| team|:\n",
      "\n",
      "|###| History|\n",
      "|-| **|Founded|:**| |194|6| as| a| charter| member| of| the| All|-Amer|ica| Football| Conference| (|AA|FC|)| and| joined| the| NFL| in| |194|9| when| the| leagues| merged|.\n",
      "|-| **|Team| Name|:**| The| name| \"|49|ers|\"| is| a| reference| to| the| prospect|ors| who| arrived| in| Northern| California| during| the| |184|9| Gold| Rush|.\n",
      "\n",
      "|###| Ach|ievements|\n",
      "|-| **|Super| Bowl| Championships|:**| The| |49|ers| have| won| five| Super| Bowl| titles| (|X|VI|,| XIX|,| XX|III|,| XX|IV|,| and| XX|IX|).\n",
      "|-| **|Conference| Championships|:**| They| have| won| the| NFC| Championship| seven| times|.\n",
      "|-| **|Division| Championships|:**| The| team| has| numerous| NFC| West| division| titles|.\n",
      "\n",
      "|###| Not|able| Figures|\n",
      "|-| **|Co|aches|:**| Bill| Walsh|,| who| is| credited| with| developing| the| \"|West| Coast| offense|,\"| is| one| of| the| most| famous| coaches| in| |49|ers| history|.\n",
      "|-| **|Players|:**| The| team| has| had| several| Hall| of| Fame| players|,| including| Joe| Montana|,| Jerry| Rice|,| Steve| Young|,| Ronnie| L|ott|,| and| many| others|.\n",
      "\n",
      "|###| Stadium|\n",
      "|-| **|Le|vi|'s| Stadium|:**| Located| in| Santa| Clara|,| California|,| it| has| been| the| team's| home| since| |201|4|.| Before| that|,| they| played| at| Cand|lestick| Park| in| San| Francisco|.\n",
      "\n",
      "|###| Rival|ries|\n",
      "|-| **|Dallas| Cowboys|:**| One| of| the| most| stor|ied| rival|ries|,| especially| prominent| during| the| |198|0|s| and| |199|0|s|.\n",
      "|-| **|Seattle| Seahawks|:**| A| more| recent| but| intense| rivalry|,| particularly| since| the| Seahawks| joined| the| NFC| West| in| |200|2|.\n",
      "|-| **|Los| Angeles| Rams|:**| A| long|-standing| divis|ional| rivalry|.\n",
      "\n",
      "|###| Recent| Performance|\n",
      "|-| The| |49|ers| have| had| periods| of| both| success| and| struggle| in| recent| years|.| They| reached| the| Super| Bowl| in| the| |201|9| season| but| lost| to| the| Kansas| City| Chiefs|.| The| team| has| been| competitive| in| the| NFC| West| and| continues| to| build| a| strong| roster|.\n",
      "\n",
      "|###| Ownership| and| Management|\n",
      "|-| **|Owner|:**| The| team| is| owned| by| Denise| De|Bart|olo| York| and| John| York|,| with| their| son| Jed| York| serving| as| the| CEO|.\n",
      "|-| **|General| Manager|:**| John| Lynch|,| a| former| NFL| player| and| Hall| of| F|amer|,| has| been| the| GM| since| |201|7|.\n",
      "|-| **|Head| Coach|:**| Kyle| Shan|ahan|,| known| for| his| offensive| ac|umen|,| has| been| the| head| coach| since| |201|7|.\n",
      "\n",
      "|The| |49|ers| are| known| for| their| rich| history|,| iconic| players|,| and| significant| contributions| to| the| game| of| football|.| They| continue| to| be| a| prominent| and| competitive| team| in| the| NFL|.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1ef6a3d0-41eb-66f4-a311-8ebdfa1b281f'})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-b5862486-a25f-48fc-9a03-a8506a6692a8', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'example': False} id='f51807de-6b99-4da4-a798-26cf59d16412'\n",
      "=========================\n",
      "content='' additional_kwargs={'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-fa4ab1c6-274d-4be5-8c4a-a6411c7c35cc' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {}, 'status': 'success'} name='multiply' id='3e7bbfb6-aa82-453a-969c-9c753fbd1d74' tool_call_id='call_imZHAw7kvMR2ZeKaQVSlj25C'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-e8e0d672-cfb2-42be-850a-345df3718f69'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1ef6a3da-687f-6253-915a-701de5327165\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "--------------------------------------------------\n",
      "AI: The result of\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
